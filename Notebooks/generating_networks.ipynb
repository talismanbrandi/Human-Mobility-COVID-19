{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from ast import literal_eval\n",
    "import math\n",
    "import time\n",
    "from statistics import geometric_mean\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import collections, functools, operator\n",
    "import re"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def occupancy(df_test, df_base, place_types_list=[]):\n",
    "    \"\"\" Slice function for separating places into place types and calculating the occupancy\n",
    "    :param df_test: the dataframe with the data for the current month\n",
    "    :param df_base: the dataframe with the data for the baseline month\n",
    "    :param place_types_list: the list of place types to be sliced. If left empty it returns all\n",
    "                             placetypes present in df_test AND df_base\n",
    "    :return dict_df: a dictionary with keys corresponding to all the place types and values corresponding to the dataframes\n",
    "    \"\"\"\n",
    "    dict_df = {}\n",
    "    if not place_types_list:\n",
    "        place_types_list_1 = list(df_test['top_category'].unique())\n",
    "        place_types_list_2 = list(df_base['top_category'].unique())\n",
    "        place_types = [value for value in place_types_list_1 if value in place_types_list_2 and str(value) != 'nan']\n",
    "    else: place_types = place_types_list\n",
    "    \n",
    "    for placeType in place_types:\n",
    "        df = df_test[df_test['top_category'].str.contains(placeType, na=False)]\n",
    "        df = pd.merge(df, df_base[df_base['top_category'].str.contains(placeType, na=False)][['safegraph_place_id', 'popularity_by_day']], on='safegraph_place_id')\n",
    "        df['popularity_by_day_x'] = df['popularity_by_day_x'].apply(lambda x: np.sum(list(literal_eval(x).values())))\n",
    "        df['popularity_by_day_y'] = df['popularity_by_day_y'].apply(lambda x: np.sum(list(literal_eval(x).values())))\n",
    "        df['occupancy'] = df['popularity_by_day_x']/df['popularity_by_day_y']*100\n",
    "        dict_df[placeType] = df\n",
    "    \n",
    "    return dict_df\n",
    "\n",
    "\n",
    "def distance(lat1, lon1, lat2, lon2):\n",
    "    r = 6372.8 # radius of earth in km\n",
    "    dLat = math.radians(lat2 - lat1)\n",
    "    dLon = math.radians(lon2 - lon1)\n",
    "    lat1 = math.radians(lat1)\n",
    "    lat2 = math.radians(lat2)\n",
    "    a = math.sin(dLat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(dLon / 2) ** 2\n",
    "    c = 2 * math.asin(math.sqrt(a))\n",
    "    return r * c\n",
    "\n",
    "\n",
    "def approx_distance(lat1, lon1, lat2, lon2):\n",
    "\n",
    "    dLat = lat2 - lat1\n",
    "    dLon = lon2 - lon1\n",
    "    \n",
    "    a = (dLat / 2) ** 2 + (1 - lat1 * lat1 /4) * (1 - lat2 * lat2 /4) * ((dLon / 2) ** 2)\n",
    "    return a\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Population Flow Data for NYC"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# keys = ['2019_01', '2019_02', '2019_03', '2019_04', '2019_05', '2019_06', '2019_07', '2019_08', '2019_09', '2019_10', '2019_11', '2019_12',\n",
    "#         '2020_01', '2020_02', '2020_03', '2020_04', '2020_05', '2020_06', '2020_07', '2020_08', '2020_09', '2020_10', '2020_11', '2020_12',]\n",
    "\n",
    "keys = ['2019_01', '2019_04', '2020_04']\n",
    "\n",
    "dict_df = {}\n",
    "dict_df_NYC = {}\n",
    "\n",
    "for key in keys:\n",
    "    dict_df[key] = pd.read_csv('../datasets/NYC/NYC_'+key+'.csv.tar.gz', compression='gzip')\n",
    "    \n",
    "dfC_2020_04 = pd.read_csv('../datasets/NYC/Core-NYC_2020_04.csv.tar.gz', compression='gzip')\n",
    "\n",
    "for key in keys:\n",
    "    dict_df_NYC[key] = pd.merge(dfC_2020_04[dfC_2020_04['city']=='New York'],\n",
    "                                dict_df[key][dict_df[key]['city']=='New York'], on='safegraph_place_id')\n",
    "    \n",
    "\n",
    "dump = False\n",
    "if dump:\n",
    "    with open('../datasets/place_types.json', 'w') as f:\n",
    "        json.dump(pd.DataFrame(np.sort(dict_df_NYC[keys[0]]['top_category'].dropna().unique()), columns=[\"place_type\"]).to_dict(orient='dict'), f, indent=4)\n",
    "    \n",
    "with open('../datasets/place_types.json', 'r') as f:\n",
    "    place_types = json.load(f)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compute Occupancy for POIs "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/Users/hkim78/Library/Python/3.8/lib/python/site-packages/pandas/core/strings.py:2001: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# place_types_list = ['Restaurants', 'Grocery', 'Clothing Stores']\n",
    "dict_df_analysis = {}\n",
    "\n",
    "for key in keys[1:]:\n",
    "    # dict_df_analysis[key] = occupancy(dict_df_NYC[key], dict_df_NYC['2019_01'], place_types_list)\n",
    "    dict_df_analysis[key] = occupancy(dict_df_NYC[key], dict_df_NYC['2019_01'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Concatenate data frame for all place types ('top_category')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "dfm = pd.concat([dict_df_analysis['2019_04'][i] for i in dict_df_analysis['2019_04'].keys()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['safegraph_place_id', 'state_x', 'countyName_x',\n       'parent_safegraph_place_id_x', 'location_name_x', 'brands_x',\n       'top_category', 'sub_category', 'naics_code', 'latitude', 'longitude',\n       'street_address_x', 'city_x', 'postal_code_x', 'open_hours',\n       'category_tags', 'state_y', 'countyName_y', 'placekey',\n       'parent_placekey', 'parent_safegraph_place_id_y', 'location_name_y',\n       'street_address_y', 'city_y', 'postal_code_y', 'brands_y',\n       'date_range_start', 'date_range_end', 'raw_visit_counts',\n       'raw_visitor_counts', 'visits_by_day', 'poi_cbg', 'visitor_home_cbgs',\n       'visitor_daytime_cbgs', 'visitor_country_of_origin',\n       'distance_from_home', 'median_dwell', 'bucketed_dwell_times',\n       'related_same_day_brand', 'related_same_month_brand',\n       'popularity_by_hour', 'popularity_by_day_x', 'device_type',\n       'popularity_by_day_y', 'occupancy'],\n      dtype='object')"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 6
    }
   ],
   "source": [
    "dfm.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compute Distance between every pair of POIs "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "dfm = dfm[['safegraph_place_id', 'latitude', 'longitude', 'occupancy', \n",
    "           'top_category', 'sub_category', 'naics_code', 'poi_cbg', 'visitor_home_cbgs', 'distance_from_home']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# dfm[:10]\n",
    "# \n",
    "# dfm[dfm['safegraph_place_id'] == 'sg:e2e1a315f7e84868a56778e9252c0e05']['latitude'].values[0]\n",
    "# \n",
    "# a = dfm['safegraph_place_id'].tolist()\n",
    "# len(a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "time 0.9169559478759766\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\n",
    "## compute the distance between every pair of POIs #approximate distance \n",
    "\n",
    "rel_prob = dict()\n",
    "c = 0\n",
    "s  = time.time()\n",
    "\n",
    "list_poi = dfm['safegraph_place_id'].tolist()[:10]\n",
    "for p1 in range(len(list_poi)):\n",
    "    for p2 in range(len(list_poi)):\n",
    "\n",
    "        if p1 == p2 or p1 < p2:\n",
    "            continue\n",
    "\n",
    "        lat1 = dfm[dfm['safegraph_place_id'] == list_poi[p1]]['latitude'].values[0] \n",
    "        lon1 = dfm[dfm['safegraph_place_id'] == list_poi[p1]]['longitude'].values[0] \n",
    "        lat2 = dfm[dfm['safegraph_place_id'] == list_poi[p2]]['latitude'].values[0] \n",
    "        lon2 = dfm[dfm['safegraph_place_id'] == list_poi[p2]]['longitude'].values[0]\n",
    "\n",
    "        op1 = dfm[dfm['safegraph_place_id'] == list_poi[p1]]['occupancy'].values[0] \n",
    "        op2 = dfm[dfm['safegraph_place_id'] == list_poi[p2]]['occupancy'].values[0]\n",
    "\n",
    "        rel_prob[(p1,p2)] = geometric_mean([op1, op2]) / approx_distance(lat1, lon1, lat2, lon2)  \n",
    "        c += rel_prob[(p1,p2)]\n",
    "\n",
    "e = time.time()\n",
    "print(\"time\", e-s )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "time 65.66853928565979\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "### compute the distance between every pair of POIs #exact distance\n",
    "\n",
    "rel_prob = dict()\n",
    "c = 0 \n",
    "\n",
    "s  = time.time()\n",
    "\n",
    "list_poi = dfm['safegraph_place_id'].tolist()[:100]\n",
    "for p1 in range(len(list_poi)):\n",
    "    for p2 in range(len(list_poi)):\n",
    "\n",
    "        if p1 == p2 or p1 < p2:\n",
    "            continue\n",
    "            \n",
    "        lat1 = dfm[dfm['safegraph_place_id'] == list_poi[p1]]['latitude'].values[0] \n",
    "        lon1 = dfm[dfm['safegraph_place_id'] == list_poi[p1]]['longitude'].values[0] \n",
    "        lat2 = dfm[dfm['safegraph_place_id'] == list_poi[p2]]['latitude'].values[0] \n",
    "        lon2 = dfm[dfm['safegraph_place_id'] == list_poi[p2]]['longitude'].values[0]\n",
    "        \n",
    "        op1 = dfm[dfm['safegraph_place_id'] == list_poi[p1]]['occupancy'].values[0] \n",
    "        op2 = dfm[dfm['safegraph_place_id'] == list_poi[p2]]['occupancy'].values[0]\n",
    "\n",
    "        rel_prob[(p1,p2)] = geometric_mean([op1, op2]) / distance(lat1, lon1, lat2, lon2) \n",
    "        c += rel_prob[(p1,p2)]\n",
    "        \n",
    "e = time.time()\n",
    "print(\"time\", e-s )\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "time 16.475069999694824\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "### compute geometric mean only \n",
    "\n",
    "rel_prob = dict()\n",
    "c = 0 \n",
    "\n",
    "s  = time.time()\n",
    "\n",
    "list_poi = dfm['safegraph_place_id'].tolist()[:100]\n",
    "for p1 in range(len(list_poi)):\n",
    "    for p2 in range(len(list_poi)):\n",
    "\n",
    "        if p1 == p2 or p1 < p2:\n",
    "            continue\n",
    "        \n",
    "        op1 = dfm[dfm['safegraph_place_id'] == list_poi[p1]]['occupancy'].values[0] \n",
    "        op2 = dfm[dfm['safegraph_place_id'] == list_poi[p2]]['occupancy'].values[0]\n",
    "\n",
    "        rel_prob[(p1,p2)] = geometric_mean([op1, op2]) \n",
    "        c += rel_prob[(p1,p2)]\n",
    "        \n",
    "e = time.time()\n",
    "print(\"time\", e-s )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    " \n",
    "# linkData = pd.DataFrame({'source' : ['Amy', 'Bob'],\n",
    "#                   'target' : ['Bob', 'Cindy'],\n",
    "#                   'weight' : [100, 50]})\n",
    "# \n",
    "# nodeData = pd.DataFrame({'name' : ['Amy', 'Bob', 'Cindy'],\n",
    "#                   'type' : ['Foo', 'Bar', 'Baz'],\n",
    "#                   'gender' : ['M', 'F', 'M']})\n",
    "# \n",
    "# G = nx.from_pandas_edgelist(linkData, 'source', 'target', True, nx.DiGraph())\n",
    "# nx.set_node_attributes(G, nodeData.set_index('name').to_dict('index'))\n",
    "# \n",
    "# \n",
    "# G.nodes(data=True)\n",
    "# \n",
    "# \n",
    "# nodeData.set_index('name').to_dict('index')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}